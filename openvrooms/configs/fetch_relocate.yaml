# scene
scene: relocate
scene_id: scene0420_01
load_texture: true
obj_num: 1 #2
duplicated_objects: true

# robot
robot: Fetch
agent_initial_pos: [-1.6, -1, 0]
agent_initial_orn: [0, 0, 0]
body_width: 0.5  # diameter of base link

# action space
is_discrete: true #false
wheel_velocity: 0.5 # normalized wheel velocity
move_distance: 0.1  #0.05
turn_angle: 0.1 #0.03
joint_control: true

# objects: pos:[x,y], orn: eular angles
obj_initial_pos: [[-0.5, -0.5]] #[[1, 1], [2, 2]], [[-1, -1]]
obj_initial_orn: [[0, 0, 0]] #[[0, 0, 0], [0, 0, 0]]
obj_target_pos: [[1.5, 1]] #[[-1, -1], [-2, -2]]
obj_target_orn: [[0, 0, 0]] #[[0, 0, 0], [0, 0, 0]]
obj_mass: [10]
floor_friction: [0.1]

# observation space: sensor spec
output: [task_obs]  # if learning, can only handle single modal  #task_obs or rgb
third_person_view: true
external_camera_pos: [2, -0.3, 2.3] #[2, 0, 2.3] #[1, 0, 2.3] 
external_camera_view_direction: [-0.4, 0.0, -0.4] #[-0.4, 0.3, -0.9] #[-0.3, 0, -0.8] #[-0.5, 0, -0.6] 

#external_camera_pos: [1.79087593, -1.50272334, 1.88004946]
#external_camera_view_direction: [-0.69855025, 0.58615326, -0.9]
image_width: 84
image_height: 84

# task
task: relocate_goal_fixed
goal_format: cartesian
task_obs_dim: 6 # basic dimensions in state, addtional dimensions 6 per object

# reward
use_goal_dist_reward: false
rot_dist_reward_weight: 0.0 # (position distance reward weight is 1)
goal_dist_reward_weight: 1.0 # should > 0

success_reward: 100.0 #800.0
dist_tol: 0.25 #0.1 # l2 distance in meter
angle_tol: 0.2 # eular angle distance ?

collision_penalty: -10.0
collision_reward: -0.5 #1.0 #0.2 #-0.1
time_elapse_reward: -1.0 #0.0
out_of_bound_reward: -1000.0

# use energy in reward function
use_energy_cost: false
#energy_cost_scale: 1.0
normalized_energy: false #false  # for joint level energy
joint_level_energy: true # false: pushing energy
history_energy_ratio: false # false: method of paper

# episode termination condition
max_step: 400
max_collisions_allowed: 100

# misc config
collision_ignore_link_a_ids: [0, 1, 2]  # ignore collisions with these robot links
visual_object_visible_to_agent: false # visual target landmarks

# simulation
action_timestep: 0.1  # environment executes action per action_timestep second, 1/10
#physics_timestep: 0.004 #0.025 # physics timestep for pybullet, 1/40=0.025, 1/250=0.004
initial_pos_z_offset: 0.1

#-----------------------------------------------------------------------------------------
# rl for ALL
# general training settings
# training_timesteps: 40000
# discount_factor: 0.99
# learning_rate: 0.001
# minibatch_size: 64
# frame_stack: 4

# # dqn
# update_frequency: 1
# target_update_frequency: 100
# replay_start_size: 1000
# replay_buffer_size: 10000
# initial_exploration: 1.0
# final_exploration: 0.0
# final_exploration_frame: 10000




