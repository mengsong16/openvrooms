# scene
scene: relocate_different_objects # could change object material
scene_id: scene0420_01
load_texture: true
obj_num: 2
duplicated_objects: true

# robot
robot: Fetch
agent_initial_pos: [0, 0, 0] 
agent_initial_orn: [0, 0, 0]
body_width: 0.5  # diameter of base link

# action space
is_discrete: true #false
wheel_velocity: 0.5 # normalized wheel velocity
move_distance: 0.1  #0.05
turn_angle: 0.1 #0.03
joint_control: true

# objects: pos:[x,y], orn: eular angles
obj_initial_pos: [[0.7, 0.7], [0.7, -0.7]] #[[0.7, 0.4], [0.7, -0.4]]  
obj_initial_orn: [[0, 0, 0], [0, 0, 0]] 
circle_radius: [1.5] 
obj_mass: [10, 50] #[70, 10]  
obj_material: ['Material__wood_hemlock', 'Material__steel_oxydized_bright'] # ['Material__steel_oxydized_bright', 'Material__wood_hemlock']
floor_friction: [0.5]

# observation space: sensor spec
output: [task_obs]  # if learning, can only handle single modal  #task_obs or rgb
third_person_view: true
external_camera_pos: [2, -0.3, 2.3] #[2, 0, 2.3] #[1, 0, 2.3] 
external_camera_view_direction: [-0.4, 0.3, -0.9] #[-0.3, 0, -0.8] #[-0.5, 0, -0.6] 
image_width: 84
image_height: 84

# task
task: relocate_outside_circle
goal_format: cartesian
task_obs_dim: 6 # basic dimensions in state, addtional dimensions 6 per object

# reward
use_goal_dist_reward: false # true
rot_dist_reward_weight: 0.0 # (position distance reward weight is 1)
goal_dist_reward_weight: 0.1 #1.0  # should > 0

success_reward: 100.0 #800.0
dist_tol: 0.25 #0.1 # l2 distance in meter
angle_tol: 0.2 # eular angle distance ?

collision_penalty: -10.0
collision_reward: -0.5 #1.0 #0.2 #-0.1
time_elapse_reward: -1.0 #0.0
out_of_bound_reward: -1000.0
tier_cost: -1.0

use_tier_reward: false

#0_1_reward: true
reward_function_choice: '0-1' #'-1-0-push-time'
random_init_pose: true #true
swap: true
config_index: 3 # 0 - 7

# use energy in reward function
use_energy_cost: true #true 
joint_level_energy: false # false: pushing energy, true: robot output energy
normalized_energy: false #false  # for joint level energy only
ratio_method: "history" # "paper" "history" "heuristic"
heuristic_succeed_episode_energy_min: 30 # only for ratio_method is heuristic
heuristic_succeed_episode_energy_max: 250 #380 # only for ratio_method is heuristic

# episode termination condition
max_step: 400
max_collisions_allowed: 100

# misc config
collision_ignore_link_a_ids: [0, 1, 2]  # ignore collisions with these robot links
visual_object_visible_to_agent: false # visual target landmarks

# simulation
action_timestep: 0.1  # environment executes action per action_timestep second, 1/10
#physics_timestep: 0.025 # physics timestep for pybullet, 1/40
initial_pos_z_offset: 0.1

#-----------------------------------------------------------------------------------------
# rl for ALL
# general training settings
# training_timesteps: 40000
# discount_factor: 0.99
# learning_rate: 0.001
# minibatch_size: 64
# frame_stack: 4

# # dqn
# update_frequency: 1
# target_update_frequency: 100
# replay_start_size: 1000
# replay_buffer_size: 10000
# initial_exploration: 1.0
# final_exploration: 0.0
# final_exploration_frame: 10000




