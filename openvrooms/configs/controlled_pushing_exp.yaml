# ---------------------------------
# parameters need to be set here
# use navigation scene and task if no object involved
scene: navigate #relocate #navigate
task: navigate_goal_fixed #relocate_goal_fixed #navigate_goal_fixed

agent_initial_pos: [-2, 0, 0]
obj_initial_pos: [[-1.4, 0]] 
obj_target_pos: [[1, 0]]  
obj_mass: [10] 
floor_friction: [0.9]
obj_num: 1 

# normalized wheel velocity
wheel_velocity: 1 

# for joint level energy
normalized_energy: false 

# simulation
action_timestep: 0.2  # environment executes action per action_timestep second, 1/10
#physics_timestep: 0.004 # physics timestep for pybullet, 1/40
initial_pos_z_offset: 0.2

# ---------------------------------
# scene
scene_id: scene0420_01
load_texture: true
duplicated_objects: true

# robot
robot: Fetch
agent_initial_orn: [0, 0, 0]
body_width: 0.5  # diameter of base link

# action space
is_discrete: true #false
move_distance: 0.1  #0.05
turn_angle: 0.1 #0.03
joint_control: true

# objects: pos:[x,y], orn: eular angles
obj_initial_orn: [[0, 0, 0]] #[[0, 0, 0], [0, 0, 0]]
obj_target_orn: [[0, 0, 0]] #[[0, 0, 0], [0, 0, 0]]


# observation space: sensor spec
output: [task_obs]  # if learning, can only handle single modal  #task_obs or rgb
third_person_view: true
external_camera_pos: [2, -0.3, 2.3] #[2, 0, 2.3] #[1, 0, 2.3] 
external_camera_view_direction: [-0.4, 0.0, -0.4] #[-0.4, 0.3, -0.9] #[-0.3, 0, -0.8] #[-0.5, 0, -0.6] 

#external_camera_pos: [1.79087593, -1.50272334, 1.88004946]
#external_camera_view_direction: [-0.69855025, 0.58615326, -0.9]
image_width: 84
image_height: 84

# task
goal_format: cartesian
task_obs_dim: 6 # basic dimensions in state, addtional dimensions 6 per object

# reward
use_goal_dist_reward: false
rot_dist_reward_weight: 0.0 # (position distance reward weight is 1)
goal_dist_reward_weight: 1.0 # should > 0

success_reward: 100.0 #800.0
dist_tol: 0.25 #0.1 # l2 distance in meter
angle_tol: 0.2 # eular angle distance ?

collision_penalty: -10.0
collision_reward: -0.5 #1.0 #0.2 #-0.1
time_elapse_reward: -1.0 #0.0
out_of_bound_reward: -1000.0

# use energy in reward function
use_energy_cost: false
#energy_cost_scale: 1.0
joint_level_energy: true # false: pushing energy
history_energy_ratio: false # false: method of paper

# episode termination condition
max_step: 400
max_collisions_allowed: 100

# misc config
collision_ignore_link_a_ids: [0, 1, 2]  # ignore collisions with these robot links
visual_object_visible_to_agent: false # visual target landmarks

